% !TeX root = ../main.tex
% -*- coding: utf-8 -*-
% !TeX root = ../main.tex
% -*- coding: utf-8 -*-

\chapter{绪论}
\label{chpt:introduction}


广泛流行的社交网络和移动设备使人类能够对他们关于线上购买的商品和服务运用文本,图片和视频等方式评价和分享他们的观点和想法\cite{zhao2015predicting,zhao2016predicting,deriu2017leveraging,gong2017clustered,luiz2018feature,gong2018sentiment,zhao2020discrete,zhao2020end}.例如,当计划购物时,很大概率我们会看其他人对于这个商品或服务的评价.如果用户的反馈是以负面评价主导的,我们也许会转而考虑其他的品牌.对于用户生成的大规模多媒体数据进行情感分析不仅可以帮助顾客选择他们需要的物品并且还可以促使企业提高他们产品和服务的质量\cite{zhao2016predicting,chen2019emoji}.最近的研究\cite{zhang2018textual,kiritchenko2014sentiment,georgakopoulos2018convolutional,liu2018content,yadav2020sentiment,wang2018sentiment,wang2019aspect,chen2019emoji,biddle2020leveraging}已经证明了深度神经网络(DNN)在情感分析中已经取得了最前沿的表现.但是,训练一个深度神经网络并使其达到它的能力上限通常需要很大规模的标注数据,这需要大量的时间和人力资源才能得到.一个方案是在一个有标注数据的源域上面训练并在目标域上直接使用.但是由于域间隙的存在\cite{torralba2011unbiased},\textit{i.e.} 源域和目标域的分布不同,这种方案将会导致神经网络在目标域上的表现明显退化\cite{tzeng2015simultaneous,hoffman2018cycada,yue2019domain,yang2020curriculum}.最小化域间隙的领域自适应(DA)\cite{patel2015visual,sun2015survey,kouw2019review,zhao2020multi,zhao2020review}方法提供了一个替代方案：在源域上训练一个对于目标域泛化能力强的模型.
目前的领域自适应方法主要集中于单源无监督学习\cite{liu2019survey,xi2020domain},\textit{i.e.} 只有一个有标注过的源域和一个无标注的目标域.然而这些无监督领域自适应(UDA)方法当且仅当源域与目标域的域间隙相对较小时才会表现很好,在实际场景下,域间隙很大或源域的个数大于一时,它们的表现会严重退化\cite{guo2018multi,zhao2020multi}.例如,如果我们有一个目标域：厨房,其中包含用户对于碗,菜谱,平底锅和电水壶等评论,以及三个源域：书籍,电器和电影, 完美地将每个源域与目标域对齐是难以实现的.一个直观的解决方案是将三个源域的数据组合在一起成为一个源域,之后通过单源无监督领域自适应的方法对齐源域与目标域.然而这样的方法只会得到次优结果,如图1.充分探索不同源域间的复杂相关信息能够在目标域上得到更好的结果,这催生了多源域适应(MDA)方法\cite{sun2015survey,zhao2020multi}.
最近有一些深度多源域适应方法被提出,其中大部分基于对抗学习,其中包含一对特征提取器和域判别器,用来最小化特征空间中源域分布与目标域分布的JS散度(\textit{e.g.}：MDAN\cite{zhao2018adversarial},MOE\cite{guo2018multi}),还有一部分基于最小化分布差异,其中包含一个特征提取器和一个核函数,用来最小化再生希尔伯特空间中源域和目标域的分布差异损失函数(例如：MMD损失\cite{dziugaite2015training},CDD损失\cite{Kang_2019_CVPR}).这些方法主要集中于抽取不同领域的域无关特征,将每个源域与目标域分别对齐,或从统计意义上对给源域样本设置权重.这些方法虽然可以得到不同领域的域无关特征,但仍然有一些局限.首先,在特征抽取的过程中一些目标域上的与情感相关的域特征被丢失,这是因为域间共享的特征提取器旨在通过将源域和目标域样本投影到一个低维空间中来提取域无关特征,因此不会包含目标域中全部的情感相关特征,同时可以理解为这是一个压缩的不可逆过程,易导致模式崩塌\cite{zhu2017unpaired,zhao2019cycleemotiongan,hoffman2018cycada}.其次,一些现存的多源域适应方法利用域标签将源域和目标域分别对齐,这忽视了不同源域甚至同一领域的不同子域间的相互关系.这些方法在域标签不存在的情况下将会自然地退化为单源域适应并得到次优解.最后,现存的基于采样的方法集中于通过训练样本选择模型来筛选距离目标域较近的源于样本(\textit{e.g.}：MDDA\cite{zhao2020distilling},CMSS\cite{yang2020curriculum}),这并不能即时并准确地在不同的训练阶段量化样本的动态最优权重,这是因为在不同的训练阶段,模型对同一个样本的学习进度是不同的,而一个收敛的,以样本为输入,以权重为输出的样本选择模型需要在不同的训练阶段对同一个样本输入去输出不同的权重,这与收敛的定义相悖.
在这篇文章中,我提出了一个新的实例级多源域适应框架,命名为课程式循环一致性生成对抗网络(C-CycleGAN),来解决上述问题.首先,为了将源域和目标域中样本的全部信息映射到一个连续平滑的表征空间并最小化信息损失,我引入了重构方法以更好地保留信息.其次,对于编码后的源域样本表征,我利用循环一致性生成对抗网络(CycleGAN)生成了一个中间域以将混合后的源域和目标域进行对齐.为了量化一个batch中不同源域样本对于模型的重要性,我通过动态的基于模型和无模型的两种权重机制对实例级样本分配权重.情感损失函数同样会反向传播给源域到目标域的生成器来保留情感信息.我在三个基准数据集上做了大量实验：Reviews-5\cite{yu2016learning},Amazon benchmark\cite{chen2012marginalized},和Multilingual Amazon Reviews Corpus\cite{chen2019multi}.结果表明提出的C-CycleGAN模型超越了情感分类任务领域自适应的SOTA方法.
综上所述, 本片文章的贡献分为三部分：
（1）我提出了一个新的多源域适应方法,命名为课程式循环一致性生成对抗网络(C-CycleGAN)以最小化多个源域与目标域之间的域间隙.
（2）我设计了新的实例级基于模型和无模型两种权重机制,可以动态更新样本权重.利用这种方法,C-CycleGAN不需要任何域标签,并且可以更好地挖掘多源域间的复杂相互关系.实验表明利用这种方法得到的结果优于利用域标签.
（3）我在三个基准数据集上做了大量实验.与最佳的基线模型相比,C-CycleGAN在平均分类准确率这一指标上在Reviews-5,Amazon benchmark和Multilingual Amazon Reviews Corpus数据集上分别提升了1.6\%,1.2\%和13.4\%.