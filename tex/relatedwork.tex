% !TeX root = ../main.tex
% -*- coding: utf-8 -*-


\chapter{相关工作} 
\label{chpt:relatedwork}

\textbf{文本情感分类} 文本情感分类或意见挖掘旨在从文本方面评估人们对于商品,
服务或组织的观点,情感和态度\cite{zhang2018deep}. 诸如商品评论,论坛讨论和微信等广泛流
行的社交网络促成了这一任务的迅速发展\cite{zhang2018deep,chen2019emoji}. 传统的情感分析方法主
要专注于设计人工特征\cite{pang2008opinion,mohammad2013nrc},将其送入标准的分类器,例如SVM. 近年
情感分析的工作主要基于深度神经网络\cite{zhang2018deep,wang2018sentiment},其已经胜任了许多自然语
言处理任务. 一些广泛应用于情感分析的深度模型包括递归自编码器\cite{socher2011semi,dong2014adaptive,qian2015learning},
递归神经张量网络\cite{socher2013recursive},循环神经网络(RNN)\cite{cho2014learning},长短期记忆神经网络(LSTM)\cite{hochreiter1997long},
树状LSTM\cite{tai2015improved},RNN编码解码结构\cite{cho2014learning}和BERT\cite{devlin2019bert}. 上述监督学习方法通常需要大
规模的标注数据进行训练. 然而高质量的情感标签通常需要消耗大量的时间和人力
资源才能得到. 在C-CycleGAN中,我应用了双向LSTM(Bi-LSTM)\cite{hochreiter1997long}作为编码器
和一个多层感知机作为最终情感分类任务的分类器. \\
\textbf{单源无监督域适应} 近年单源无监督域适应(SUDA)方法大多主要采用包含两条尾部相
连的数据流的深度神经网络\cite{zhuo2017deep,zhao2018adversarial}. 一条数据流在带标记数据的源域上用传统的
目标任务损失函数进行训练,例如分类任务的交叉熵损失(cross entropy loss). 
另一条数据流旨在通过不同的对齐损失函数(alignment loss)将源域与目标域进行
对齐以解决域间隙问题,例如分布差异损失(discrepancy loss),对抗损失(adversarial loss)
和自监督损失(self-supervised loss)\emph{etc}. 基于分布差异的方法采用一些距离度
量来最小化源域和目标域在特定空间的差异,例如最大期望差异\cite{long2015learning,wang2018multi,xi2020domain},相
关性对齐\cite{sun2016return,sun2017correlation,zhuo2017deep}和对比领域差异\cite{kang2019contrastive}. 对比判别模型
(adversarial discriminative model)通常采用一个域判别器以对抗地对齐从
源域和目标域中抽取的特征来使他们无法判别\cite{ganin2016domain,tzeng2017adversarial,chen2017no,shen2017wasserstein,tsai2018learning,huang2018domain,kumar2019adversarial,wu2020unsupervised}. 
除了域判别器,对抗生成模型(adversarial generative model)还包含一个生成部分
,基于生成对抗网络(GAN)\cite{goodfellow2014generative}和它的变体,例如CoGAN\cite{liu2016coupled}, SimGAN\cite{shrivastava2017learning}和
CycleGAN\cite{zhu2017unpaired,zhao2019cycleemotiongan,hoffman2018cycada}以生成假源域或目标域样本. 基于自监督的模型在原始的目
标任务网络中融入了辅助的自监督学习任务以使源域和目标域靠近. 通常使用的自监
督任务包括重构(reconstruction)\cite{ghifary2015domain,ghifary2016deep,chen2020fido},图像旋转预测(image rotation prediction)\cite{sun2019unsupervised,xu2019self}
,拼图预测(jigsaw prediction)\cite{carlucci2019domain},和掩码(masking)\cite{vu2020effective}. 尽管这些方法在
SUDA任务中达到了满意的效果,他们的表现在应用于多源域适应任务时会大幅衰减. \\
\textbf{多源域适应} 基于一些理论分析\cite{ben2010theory,hoffman2018algorithms},多源域适应旨在更好地解决训练数据属于
多个源域的问题\cite{sun2015survey,zhao2019multi}. 早期的多源域适应方法主要分为两种\cite{sun2015survey,sun2011two,duan2012exploiting,chattopadhyay2012multisource,duan2012domain}以及预训练分类器的组合\cite{xu2012multi,sun2013bayesian}. 近年的方法考虑了一些特殊的
多源域适应场景,例如不完全多源域适应\cite{ding2018incomplete}和目标域偏移\cite{redko2019optimal}. 
最近一些基于深度表示学习的多源域适应方法被提出,例如多源对抗网络(MDAN)\cite{zhao2018adversarial},
深度混合网络(DCTN)\cite{xu2018deep},混合专家模型(MoE)\cite{guo2018multi},时矩匹配网络(MMN)\cite{peng2019moment},
多源对抗聚合网络(MADAN)\cite{zhao2019multi},多源蒸馏模型(MDDA)\cite{zhao2020distilling}和课程式源域选择模型(CMSS)\cite{yang2020curriculum}. 
MDAN,DCTN,MoE,MMN,MADAN和MDDA都需要源域样本的域标签. MDDA和CMSS利用
了静态权重机制选择距离目标域较近的源域样本,而其他模型并没有考虑不同源域样
本的重要性. 用于情感分类的的多源域适应方法,\textit{e.g.}MDAN和MoE仅仅集中于抽取域无
关特征,这将导致目标域中与情感相关的域特征被丢失. 区别于这些方法,对于源域
样本,我利用循环一致性和情感一致性生成了一个距离目标域较近的中间域. 更进一
步地,我提出实例级动态权重机制,在不需要域标签的情况下对源域样本分配权重. 